[03:11:08.895] Namespace(base_lr=0.01, batch_size=2, beta=0.01, class_weight=None, conf_thresh=0.95, dataset='SkullScalp_t1', deterministic=1, device='cuda', exp='T1_SkullScalp_t1256', img_size=256, is_pretrain=False, loss='BCE', max_epochs=150, max_iterations=300, n_gpu=1, n_skip=3, num_classes=9, resume=0, root_path='./train_t1t2.h5', seed=1234, suffix='', vit_name='R50-ViT-B_16', vit_patches_size=16, warmup=0)
[03:11:08.928] 43680.0 iterations per epoch. 6552000.0 max iterations 
[03:11:13.856] iteration 1 : loss : 1.399579, loss_x: 2.030046, loss_u_s1: 1.007713, loss_u_s2: 1.007713, loss_u_w_fp: 0.530511
[03:11:14.340] iteration 2 : loss : 1.046611, loss_x: 1.994054, loss_u_s1: 0.128248, loss_u_s2: 0.128248, loss_u_w_fp: 0.070089
[03:11:14.766] iteration 3 : loss : 1.171043, loss_x: 2.000998, loss_u_s1: 0.617122, loss_u_s2: 0.617122, loss_u_w_fp: 0.065052
[03:11:15.191] iteration 4 : loss : 1.266855, loss_x: 2.063703, loss_u_s1: 0.890501, loss_u_s2: 0.890501, loss_u_w_fp: 0.049513
[03:11:15.618] iteration 5 : loss : 1.063409, loss_x: 2.058208, loss_u_s1: 0.118811, loss_u_s2: 0.118811, loss_u_w_fp: 0.018408
[03:11:16.025] iteration 6 : loss : 1.094048, loss_x: 2.028403, loss_u_s1: 0.296971, loss_u_s2: 0.296971, loss_u_w_fp: 0.022414
[03:11:16.462] iteration 7 : loss : 1.066357, loss_x: 2.023541, loss_u_s1: 0.202706, loss_u_s2: 0.202706, loss_u_w_fp: 0.015641
[03:11:16.889] iteration 8 : loss : 1.054483, loss_x: 2.041323, loss_u_s1: 0.098697, loss_u_s2: 0.098697, loss_u_w_fp: 0.036587
[03:11:17.314] iteration 9 : loss : 1.012512, loss_x: 1.982332, loss_u_s1: 0.034782, loss_u_s2: 0.034782, loss_u_w_fp: 0.050601
[03:11:17.744] iteration 10 : loss : 1.043397, loss_x: 1.945556, loss_u_s1: 0.218069, loss_u_s2: 0.218069, loss_u_w_fp: 0.064408
[03:11:18.161] iteration 11 : loss : 1.103426, loss_x: 1.934914, loss_u_s1: 0.443868, loss_u_s2: 0.443868, loss_u_w_fp: 0.100006
[03:11:18.581] iteration 12 : loss : 1.068211, loss_x: 1.921584, loss_u_s1: 0.366362, loss_u_s2: 0.366362, loss_u_w_fp: 0.063315
[03:11:19.003] iteration 13 : loss : 1.007785, loss_x: 1.870226, loss_u_s1: 0.232581, loss_u_s2: 0.232581, loss_u_w_fp: 0.058106
[03:11:19.556] iteration 14 : loss : 1.020746, loss_x: 1.939760, loss_u_s1: 0.178132, loss_u_s2: 0.178132, loss_u_w_fp: 0.025331
[03:11:20.101] iteration 15 : loss : 1.075991, loss_x: 1.854208, loss_u_s1: 0.550844, loss_u_s2: 0.550844, loss_u_w_fp: 0.044706
[03:11:20.554] iteration 16 : loss : 1.081733, loss_x: 1.946596, loss_u_s1: 0.395324, loss_u_s2: 0.395324, loss_u_w_fp: 0.038418
[03:11:21.002] iteration 17 : loss : 0.952774, loss_x: 1.777136, loss_u_s1: 0.229100, loss_u_s2: 0.229100, loss_u_w_fp: 0.027723
[03:11:21.460] iteration 18 : loss : 0.912171, loss_x: 1.704519, loss_u_s1: 0.204602, loss_u_s2: 0.204602, loss_u_w_fp: 0.035044
[03:11:21.881] iteration 19 : loss : 0.884898, loss_x: 1.607105, loss_u_s1: 0.278350, loss_u_s2: 0.278350, loss_u_w_fp: 0.047033
[03:11:22.314] iteration 20 : loss : 0.952496, loss_x: 1.834345, loss_u_s1: 0.106696, loss_u_s2: 0.106696, loss_u_w_fp: 0.034597
[03:11:22.788] iteration 21 : loss : 0.866949, loss_x: 1.602078, loss_u_s1: 0.228671, loss_u_s2: 0.228671, loss_u_w_fp: 0.034969
[03:11:23.278] iteration 22 : loss : 0.783357, loss_x: 1.508301, loss_u_s1: 0.081916, loss_u_s2: 0.081916, loss_u_w_fp: 0.034912
[03:11:23.747] iteration 23 : loss : 0.900332, loss_x: 1.733975, loss_u_s1: 0.095404, loss_u_s2: 0.095404, loss_u_w_fp: 0.037975
[03:11:24.238] iteration 24 : loss : 0.830558, loss_x: 1.552947, loss_u_s1: 0.159216, loss_u_s2: 0.159216, loss_u_w_fp: 0.057123
[03:11:24.688] iteration 25 : loss : 0.767008, loss_x: 1.285441, loss_u_s1: 0.450451, loss_u_s2: 0.450451, loss_u_w_fp: 0.046699
[03:11:25.146] iteration 26 : loss : 0.772401, loss_x: 1.414227, loss_u_s1: 0.214470, loss_u_s2: 0.214470, loss_u_w_fp: 0.046677
[03:11:25.580] iteration 27 : loss : 0.850397, loss_x: 1.590141, loss_u_s1: 0.181531, loss_u_s2: 0.181531, loss_u_w_fp: 0.039777
[03:11:26.017] iteration 28 : loss : 0.817976, loss_x: 1.547757, loss_u_s1: 0.137039, loss_u_s2: 0.137039, loss_u_w_fp: 0.039349
[03:11:26.454] iteration 29 : loss : 0.742455, loss_x: 1.318720, loss_u_s1: 0.292654, loss_u_s2: 0.292654, loss_u_w_fp: 0.039725
[03:11:26.904] iteration 30 : loss : 0.792494, loss_x: 1.516088, loss_u_s1: 0.037432, loss_u_s2: 0.037432, loss_u_w_fp: 0.100367
[03:11:27.355] iteration 31 : loss : 0.799399, loss_x: 1.496158, loss_u_s1: 0.176037, loss_u_s2: 0.176037, loss_u_w_fp: 0.029242
[03:11:27.783] iteration 32 : loss : 0.740993, loss_x: 1.383252, loss_u_s1: 0.175835, loss_u_s2: 0.175835, loss_u_w_fp: 0.021632
[03:11:28.232] iteration 33 : loss : 0.800117, loss_x: 1.487108, loss_u_s1: 0.193750, loss_u_s2: 0.193750, loss_u_w_fp: 0.032501
[23:07:31.897] Namespace(base_lr=0.01, batch_size=2, beta=0.01, class_weight=None, conf_thresh=0.95, dataset='SkullScalp_t1', deterministic=1, device='cuda', exp='T1_SkullScalp_t1256', img_size=256, is_pretrain=False, loss='BCE', max_epochs=150, max_iterations=300, n_gpu=2, n_skip=3, num_classes=9, resume=0, root_path='./train_t1t2.h5', seed=1234, suffix='', vit_name='R50-ViT-B_16', vit_patches_size=16, warmup=0)
[23:07:31.943] 43680.0 iterations per epoch. 6552000.0 max iterations 
[23:07:36.833] iteration 1 : loss : 1.399579, loss_x: 2.030046, loss_u_s1: 1.007713, loss_u_s2: 1.007713, loss_u_w_fp: 0.530511
[23:07:37.336] iteration 2 : loss : 1.046813, loss_x: 1.994064, loss_u_s1: 0.129411, loss_u_s2: 0.129411, loss_u_w_fp: 0.069711
[23:07:37.828] iteration 3 : loss : 1.175633, loss_x: 2.001410, loss_u_s1: 0.633572, loss_u_s2: 0.633572, loss_u_w_fp: 0.066140
[23:07:38.283] iteration 4 : loss : 1.275121, loss_x: 2.063144, loss_u_s1: 0.924500, loss_u_s2: 0.924500, loss_u_w_fp: 0.049696
[23:07:38.745] iteration 5 : loss : 1.067797, loss_x: 2.062141, loss_u_s1: 0.128081, loss_u_s2: 0.128081, loss_u_w_fp: 0.018828
[23:07:39.200] iteration 6 : loss : 1.103385, loss_x: 2.028972, loss_u_s1: 0.316903, loss_u_s2: 0.316903, loss_u_w_fp: 0.038693
[23:07:39.638] iteration 7 : loss : 1.089222, loss_x: 2.028236, loss_u_s1: 0.277536, loss_u_s2: 0.277536, loss_u_w_fp: 0.022879
[23:07:40.127] iteration 8 : loss : 1.058396, loss_x: 2.053661, loss_u_s1: 0.091902, loss_u_s2: 0.091902, loss_u_w_fp: 0.034358
[23:07:40.579] iteration 9 : loss : 1.028651, loss_x: 2.012700, loss_u_s1: 0.040814, loss_u_s2: 0.040814, loss_u_w_fp: 0.048389
[23:07:41.060] iteration 10 : loss : 1.018863, loss_x: 1.964600, loss_u_s1: 0.113094, loss_u_s2: 0.113094, loss_u_w_fp: 0.033157
[23:07:41.501] iteration 11 : loss : 1.073812, loss_x: 1.949136, loss_u_s1: 0.332768, loss_u_s2: 0.332768, loss_u_w_fp: 0.064210
[23:07:41.966] iteration 12 : loss : 1.028149, loss_x: 1.929828, loss_u_s1: 0.205281, loss_u_s2: 0.205281, loss_u_w_fp: 0.047659
[23:07:42.413] iteration 13 : loss : 0.996894, loss_x: 1.868151, loss_u_s1: 0.188867, loss_u_s2: 0.188867, loss_u_w_fp: 0.062405
[23:07:42.864] iteration 14 : loss : 1.018320, loss_x: 1.939895, loss_u_s1: 0.163158, loss_u_s2: 0.163158, loss_u_w_fp: 0.030334
[23:07:43.325] iteration 15 : loss : 0.985879, loss_x: 1.862020, loss_u_s1: 0.160540, loss_u_s2: 0.160540, loss_u_w_fp: 0.058936
[23:07:43.777] iteration 16 : loss : 1.101194, loss_x: 1.938857, loss_u_s1: 0.477056, loss_u_s2: 0.477056, loss_u_w_fp: 0.050004
[23:07:44.226] iteration 17 : loss : 0.953045, loss_x: 1.780932, loss_u_s1: 0.205727, loss_u_s2: 0.205727, loss_u_w_fp: 0.044589
[23:07:44.691] iteration 18 : loss : 0.898305, loss_x: 1.700673, loss_u_s1: 0.157284, loss_u_s2: 0.157284, loss_u_w_fp: 0.034591
[23:07:45.170] iteration 19 : loss : 0.896736, loss_x: 1.618598, loss_u_s1: 0.331361, loss_u_s2: 0.331361, loss_u_w_fp: 0.018386
[23:07:45.623] iteration 20 : loss : 0.951722, loss_x: 1.830968, loss_u_s1: 0.108552, loss_u_s2: 0.108552, loss_u_w_fp: 0.036400
[23:09:58.526] Namespace(base_lr=0.01, batch_size=2, beta=0.01, class_weight=None, conf_thresh=0.95, dataset='SkullScalp_t1', deterministic=1, device='cuda', exp='T1_SkullScalp_t1256', img_size=256, is_pretrain=False, loss='BCE', max_epochs=150, max_iterations=300, n_gpu=2, n_skip=3, num_classes=9, resume=0, root_path='./train_t1t2.h5', seed=1234, suffix='', vit_name='R50-ViT-B_16', vit_patches_size=16, warmup=0)
[23:09:58.562] 43680.0 iterations per epoch. 6552000.0 max iterations 
[23:10:02.945] iteration 1 : loss : 1.399579, loss_x: 2.030046, loss_u_s1: 1.007713, loss_u_s2: 1.007713, loss_u_w_fp: 0.530511
[23:10:03.464] iteration 2 : loss : 1.046603, loss_x: 1.994052, loss_u_s1: 0.128784, loss_u_s2: 0.128784, loss_u_w_fp: 0.069525
[23:10:03.934] iteration 3 : loss : 1.172720, loss_x: 2.001798, loss_u_s1: 0.622508, loss_u_s2: 0.622508, loss_u_w_fp: 0.064775
[23:10:04.414] iteration 4 : loss : 1.268311, loss_x: 2.063701, loss_u_s1: 0.895770, loss_u_s2: 0.895770, loss_u_w_fp: 0.050072
[23:10:04.860] iteration 5 : loss : 1.065230, loss_x: 2.056502, loss_u_s1: 0.129109, loss_u_s2: 0.129109, loss_u_w_fp: 0.018807
[23:10:05.333] iteration 6 : loss : 1.089748, loss_x: 2.024767, loss_u_s1: 0.272330, loss_u_s2: 0.272330, loss_u_w_fp: 0.037128
[23:10:05.787] iteration 7 : loss : 1.061861, loss_x: 2.016497, loss_u_s1: 0.191299, loss_u_s2: 0.191299, loss_u_w_fp: 0.023152
[23:10:06.264] iteration 8 : loss : 1.048516, loss_x: 2.035326, loss_u_s1: 0.079973, loss_u_s2: 0.079973, loss_u_w_fp: 0.043439
[23:10:06.741] iteration 9 : loss : 1.008300, loss_x: 1.973269, loss_u_s1: 0.039326, loss_u_s2: 0.039326, loss_u_w_fp: 0.047336
[23:10:07.187] iteration 10 : loss : 1.035329, loss_x: 1.938817, loss_u_s1: 0.218014, loss_u_s2: 0.218014, loss_u_w_fp: 0.045666
[23:10:07.650] iteration 11 : loss : 1.093301, loss_x: 1.943099, loss_u_s1: 0.431607, loss_u_s2: 0.431607, loss_u_w_fp: 0.055399
[23:10:08.110] iteration 12 : loss : 1.060041, loss_x: 1.926008, loss_u_s1: 0.313906, loss_u_s2: 0.313906, loss_u_w_fp: 0.074240
[23:10:08.590] iteration 13 : loss : 0.994762, loss_x: 1.864054, loss_u_s1: 0.169553, loss_u_s2: 0.169553, loss_u_w_fp: 0.081386
[23:10:09.033] iteration 14 : loss : 1.033886, loss_x: 1.954010, loss_u_s1: 0.204101, loss_u_s2: 0.204101, loss_u_w_fp: 0.023423
[23:10:09.488] iteration 15 : loss : 1.059402, loss_x: 1.853344, loss_u_s1: 0.497079, loss_u_s2: 0.497079, loss_u_w_fp: 0.033843
[23:10:09.955] iteration 16 : loss : 1.094292, loss_x: 1.940603, loss_u_s1: 0.452725, loss_u_s2: 0.452725, loss_u_w_fp: 0.043236
[23:10:10.400] iteration 17 : loss : 0.951325, loss_x: 1.770363, loss_u_s1: 0.232342, loss_u_s2: 0.232342, loss_u_w_fp: 0.032230
[23:10:10.869] iteration 18 : loss : 0.907323, loss_x: 1.689485, loss_u_s1: 0.219728, loss_u_s2: 0.219728, loss_u_w_fp: 0.030594
[23:10:11.330] iteration 19 : loss : 0.886878, loss_x: 1.582230, loss_u_s1: 0.340254, loss_u_s2: 0.340254, loss_u_w_fp: 0.042799
[23:10:11.775] iteration 20 : loss : 0.960347, loss_x: 1.822147, loss_u_s1: 0.160849, loss_u_s2: 0.160849, loss_u_w_fp: 0.036246
[23:10:28.855] Namespace(base_lr=0.01, batch_size=2, beta=0.01, class_weight=None, conf_thresh=0.95, dataset='SkullScalp_t1', deterministic=1, device='cuda', exp='T1_SkullScalp_t1256', img_size=256, is_pretrain=False, loss='BCE', max_epochs=150, max_iterations=300, n_gpu=2, n_skip=3, num_classes=9, resume=0, root_path='./train_t1t2.h5', seed=1234, suffix='', vit_name='R50-ViT-B_16', vit_patches_size=16, warmup=0)
[23:10:28.893] 43680.0 iterations per epoch. 6552000.0 max iterations 
[23:10:32.883] iteration 1 : loss : 1.399579, loss_x: 2.030046, loss_u_s1: 1.007713, loss_u_s2: 1.007713, loss_u_w_fp: 0.530511
[23:10:33.383] iteration 2 : loss : 1.047717, loss_x: 1.994048, loss_u_s1: 0.131775, loss_u_s2: 0.131775, loss_u_w_fp: 0.070998
[23:10:33.852] iteration 3 : loss : 1.180814, loss_x: 2.001072, loss_u_s1: 0.654529, loss_u_s2: 0.654529, loss_u_w_fp: 0.066583
[23:10:34.297] iteration 4 : loss : 1.271668, loss_x: 2.061677, loss_u_s1: 0.919364, loss_u_s2: 0.919364, loss_u_w_fp: 0.043953
[23:10:34.746] iteration 5 : loss : 1.071700, loss_x: 2.056271, loss_u_s1: 0.155816, loss_u_s2: 0.155816, loss_u_w_fp: 0.018441
[23:10:35.199] iteration 6 : loss : 1.090831, loss_x: 2.027934, loss_u_s1: 0.282367, loss_u_s2: 0.282367, loss_u_w_fp: 0.025089
[23:10:35.650] iteration 7 : loss : 1.061942, loss_x: 2.026780, loss_u_s1: 0.179897, loss_u_s2: 0.179897, loss_u_w_fp: 0.014313
[23:10:36.115] iteration 8 : loss : 1.044059, loss_x: 2.042310, loss_u_s1: 0.065726, loss_u_s2: 0.065726, loss_u_w_fp: 0.025890
[23:10:36.552] iteration 9 : loss : 1.014013, loss_x: 1.984518, loss_u_s1: 0.025305, loss_u_s2: 0.025305, loss_u_w_fp: 0.061710
[23:10:37.017] iteration 10 : loss : 1.027506, loss_x: 1.945871, loss_u_s1: 0.163011, loss_u_s2: 0.163011, loss_u_w_fp: 0.055270
[23:10:37.457] iteration 11 : loss : 1.051513, loss_x: 1.938671, loss_u_s1: 0.271570, loss_u_s2: 0.271570, loss_u_w_fp: 0.057140
[23:10:37.896] iteration 12 : loss : 1.024334, loss_x: 1.908460, loss_u_s1: 0.235633, loss_u_s2: 0.235633, loss_u_w_fp: 0.044782
[23:10:38.364] iteration 13 : loss : 0.980715, loss_x: 1.846049, loss_u_s1: 0.157251, loss_u_s2: 0.157251, loss_u_w_fp: 0.073512
[23:10:38.829] iteration 14 : loss : 1.013553, loss_x: 1.959315, loss_u_s1: 0.107384, loss_u_s2: 0.107384, loss_u_w_fp: 0.028197
[23:10:39.277] iteration 15 : loss : 0.953600, loss_x: 1.850882, loss_u_s1: 0.061698, loss_u_s2: 0.061698, loss_u_w_fp: 0.050938
[23:10:39.744] iteration 16 : loss : 1.132826, loss_x: 1.955772, loss_u_s1: 0.569009, loss_u_s2: 0.569009, loss_u_w_fp: 0.050751
[23:10:40.207] iteration 17 : loss : 0.934711, loss_x: 1.766730, loss_u_s1: 0.165833, loss_u_s2: 0.165833, loss_u_w_fp: 0.039553
[23:10:40.655] iteration 18 : loss : 0.895171, loss_x: 1.701639, loss_u_s1: 0.148648, loss_u_s2: 0.148648, loss_u_w_fp: 0.028759
[23:10:41.092] iteration 19 : loss : 0.872096, loss_x: 1.602792, loss_u_s1: 0.257370, loss_u_s2: 0.257370, loss_u_w_fp: 0.025430
[23:10:41.543] iteration 20 : loss : 0.935712, loss_x: 1.808586, loss_u_s1: 0.100703, loss_u_s2: 0.100703, loss_u_w_fp: 0.024975
[23:10:58.115] Namespace(base_lr=0.01, batch_size=2, beta=0.01, class_weight=None, conf_thresh=0.95, dataset='SkullScalp_t1', deterministic=1, device='cuda', exp='T1_SkullScalp_t1256', img_size=256, is_pretrain=False, loss='BCE', max_epochs=150, max_iterations=300, n_gpu=2, n_skip=3, num_classes=9, resume=0, root_path='./train_t1t2.h5', seed=1234, suffix='', vit_name='R50-ViT-B_16', vit_patches_size=16, warmup=0)
[23:10:58.152] 43680.0 iterations per epoch. 6552000.0 max iterations 
[23:11:02.156] iteration 1 : loss : 1.399579, loss_x: 2.030046, loss_u_s1: 1.007713, loss_u_s2: 1.007713, loss_u_w_fp: 0.530511
[23:11:02.689] iteration 2 : loss : 1.047810, loss_x: 1.994038, loss_u_s1: 0.131768, loss_u_s2: 0.131768, loss_u_w_fp: 0.071394
[23:11:03.173] iteration 3 : loss : 1.178583, loss_x: 2.001294, loss_u_s1: 0.643919, loss_u_s2: 0.643919, loss_u_w_fp: 0.067827
[23:11:03.643] iteration 4 : loss : 1.276336, loss_x: 2.063508, loss_u_s1: 0.927395, loss_u_s2: 0.927395, loss_u_w_fp: 0.050935
[23:11:04.102] iteration 5 : loss : 1.070349, loss_x: 2.059405, loss_u_s1: 0.148713, loss_u_s2: 0.148713, loss_u_w_fp: 0.013874
[23:11:04.548] iteration 6 : loss : 1.112460, loss_x: 2.033519, loss_u_s1: 0.352786, loss_u_s2: 0.352786, loss_u_w_fp: 0.030015
[23:11:05.007] iteration 7 : loss : 1.102309, loss_x: 2.035314, loss_u_s1: 0.313412, loss_u_s2: 0.313412, loss_u_w_fp: 0.025195
[23:11:05.440] iteration 8 : loss : 1.053768, loss_x: 2.049428, loss_u_s1: 0.086705, loss_u_s2: 0.086705, loss_u_w_fp: 0.029511
[23:11:05.889] iteration 9 : loss : 1.017377, loss_x: 2.006462, loss_u_s1: 0.020341, loss_u_s2: 0.020341, loss_u_w_fp: 0.036242
[23:11:06.343] iteration 10 : loss : 1.039441, loss_x: 1.969764, loss_u_s1: 0.167460, loss_u_s2: 0.167460, loss_u_w_fp: 0.050777
[23:11:06.803] iteration 11 : loss : 1.070852, loss_x: 1.948826, loss_u_s1: 0.305199, loss_u_s2: 0.305199, loss_u_w_fp: 0.080557
[23:11:07.278] iteration 12 : loss : 1.028466, loss_x: 1.932028, loss_u_s1: 0.200861, loss_u_s2: 0.200861, loss_u_w_fp: 0.048946
[23:11:07.731] iteration 13 : loss : 0.979636, loss_x: 1.860273, loss_u_s1: 0.157297, loss_u_s2: 0.157297, loss_u_w_fp: 0.040700
[23:11:08.174] iteration 14 : loss : 1.019614, loss_x: 1.938432, loss_u_s1: 0.167615, loss_u_s2: 0.167615, loss_u_w_fp: 0.033979
[23:11:08.605] iteration 15 : loss : 1.087928, loss_x: 1.830163, loss_u_s1: 0.639639, loss_u_s2: 0.639639, loss_u_w_fp: 0.051749
[23:11:09.056] iteration 16 : loss : 1.097389, loss_x: 1.919074, loss_u_s1: 0.497026, loss_u_s2: 0.497026, loss_u_w_fp: 0.054383
[23:11:09.514] iteration 17 : loss : 0.946799, loss_x: 1.769133, loss_u_s1: 0.212099, loss_u_s2: 0.212099, loss_u_w_fp: 0.036829
[23:11:09.974] iteration 18 : loss : 0.906318, loss_x: 1.684160, loss_u_s1: 0.213665, loss_u_s2: 0.213665, loss_u_w_fp: 0.043288
[23:11:10.437] iteration 19 : loss : 0.910373, loss_x: 1.590472, loss_u_s1: 0.424048, loss_u_s2: 0.424048, loss_u_w_fp: 0.036500
[23:11:10.899] iteration 20 : loss : 0.952293, loss_x: 1.827878, loss_u_s1: 0.116386, loss_u_s2: 0.116386, loss_u_w_fp: 0.037029
[23:11:11.386] iteration 21 : loss : 0.918013, loss_x: 1.564603, loss_u_s1: 0.506019, loss_u_s2: 0.506019, loss_u_w_fp: 0.036829
[23:11:11.866] iteration 22 : loss : 0.765887, loss_x: 1.467097, loss_u_s1: 0.088144, loss_u_s2: 0.088144, loss_u_w_fp: 0.041208
[23:11:12.336] iteration 23 : loss : 0.909833, loss_x: 1.727061, loss_u_s1: 0.134335, loss_u_s2: 0.134335, loss_u_w_fp: 0.050875
[23:11:12.801] iteration 24 : loss : 0.818523, loss_x: 1.516296, loss_u_s1: 0.182710, loss_u_s2: 0.182710, loss_u_w_fp: 0.058790
[23:11:13.261] iteration 25 : loss : 0.746659, loss_x: 1.265518, loss_u_s1: 0.427581, loss_u_s2: 0.427581, loss_u_w_fp: 0.028017
[23:11:13.717] iteration 26 : loss : 0.747973, loss_x: 1.380905, loss_u_s1: 0.193476, loss_u_s2: 0.193476, loss_u_w_fp: 0.036604
[23:11:14.185] iteration 27 : loss : 0.834399, loss_x: 1.559491, loss_u_s1: 0.190081, loss_u_s2: 0.190081, loss_u_w_fp: 0.028534
[23:11:14.652] iteration 28 : loss : 0.803493, loss_x: 1.514456, loss_u_s1: 0.158063, loss_u_s2: 0.158063, loss_u_w_fp: 0.026995
[23:11:15.101] iteration 29 : loss : 0.701483, loss_x: 1.300694, loss_u_s1: 0.174054, loss_u_s2: 0.174054, loss_u_w_fp: 0.030491
[23:11:15.568] iteration 30 : loss : 0.749899, loss_x: 1.472435, loss_u_s1: 0.034759, loss_u_s2: 0.034759, loss_u_w_fp: 0.019969
[23:11:16.045] iteration 31 : loss : 0.783305, loss_x: 1.447753, loss_u_s1: 0.181897, loss_u_s2: 0.181897, loss_u_w_fp: 0.055815
[23:11:16.504] iteration 32 : loss : 0.776377, loss_x: 1.344625, loss_u_s1: 0.374417, loss_u_s2: 0.374417, loss_u_w_fp: 0.041840
[23:11:16.981] iteration 33 : loss : 0.782219, loss_x: 1.425076, loss_u_s1: 0.254591, loss_u_s2: 0.254591, loss_u_w_fp: 0.024131
[23:11:17.466] iteration 34 : loss : 0.836051, loss_x: 1.336751, loss_u_s1: 0.635194, loss_u_s2: 0.635195, loss_u_w_fp: 0.035506
[23:11:17.920] iteration 35 : loss : 0.750658, loss_x: 1.276628, loss_u_s1: 0.397577, loss_u_s2: 0.397577, loss_u_w_fp: 0.051800
[23:11:18.358] iteration 36 : loss : 0.702921, loss_x: 1.330157, loss_u_s1: 0.128973, loss_u_s2: 0.128973, loss_u_w_fp: 0.022396
[23:11:18.810] iteration 37 : loss : 0.696828, loss_x: 1.192174, loss_u_s1: 0.366348, loss_u_s2: 0.366348, loss_u_w_fp: 0.036615
[23:11:19.261] iteration 38 : loss : 0.688429, loss_x: 1.290011, loss_u_s1: 0.159455, loss_u_s2: 0.159455, loss_u_w_fp: 0.014239
[23:11:19.729] iteration 39 : loss : 0.681277, loss_x: 1.242007, loss_u_s1: 0.208435, loss_u_s2: 0.208435, loss_u_w_fp: 0.032659
[23:11:20.179] iteration 40 : loss : 0.626316, loss_x: 1.178742, loss_u_s1: 0.119154, loss_u_s2: 0.119154, loss_u_w_fp: 0.028627
[23:11:20.681] iteration 41 : loss : 0.739601, loss_x: 1.418157, loss_u_s1: 0.109372, loss_u_s2: 0.109372, loss_u_w_fp: 0.012720
[23:11:21.138] iteration 42 : loss : 0.878735, loss_x: 1.678423, loss_u_s1: 0.130277, loss_u_s2: 0.130277, loss_u_w_fp: 0.027817
[23:11:21.611] iteration 43 : loss : 0.596485, loss_x: 1.150327, loss_u_s1: 0.072060, loss_u_s2: 0.072060, loss_u_w_fp: 0.013227
[23:11:22.066] iteration 44 : loss : 0.797228, loss_x: 1.547514, loss_u_s1: 0.081220, loss_u_s2: 0.081220, loss_u_w_fp: 0.012664
